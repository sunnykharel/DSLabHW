{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question 5",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsLKM0_sDe9C"
      },
      "source": [
        "##Question 5:\n",
        "Assuming previous tutorial has been done. We will start with our base CNN from the \"What is torch.nn\" tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEITjf-cD8dV"
      },
      "source": [
        "### Loading MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5E4scKmD3J4",
        "outputId": "d24b688e-b87f-45d5-fdf3-5284f437d637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Loading Dataset libraries\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import pickle\n",
        "import gzip\n",
        "# Computional and Graphical libraries\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "import torch\n",
        "# Debugger Library\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "URL = \"http://deeplearning.net/data/mnist/\"\n",
        "FILENAME = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (PATH / FILENAME).exists():\n",
        "        content = requests.get(URL + FILENAME).content\n",
        "        (PATH / FILENAME).open(\"wb\").write(content)\n",
        "\n",
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "  \n",
        "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
        "print(x_train.shape)\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMX9BjCDO-iJ"
      },
      "source": [
        "### Classes and Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZCog-fXHVDG"
      },
      "source": [
        "# Training and Validation Datasets/DataLoaders Libraries\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "# Optim and NN libraries\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_data(train_ds, valid_ds, bs):\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
        "        DataLoader(valid_ds, batch_size=bs * 2),\n",
        "    )\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "    loss = loss_func(model(xb), yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), len(xb)\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            loss_batch(model, loss_func, xb, yb, opt)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "            )\n",
        "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "        val_acc = sum(accuracy(model(xb), yb) for xb, yb in valid_dl)    #valid_loss / len(valid_dl)\n",
        "\n",
        "        val_acc = val_acc.numpy()\n",
        "        print(epoch, val_loss, val_acc / len(valid_dl))\n",
        "\n",
        "# This is specific to MNIST Dataset. Input is 28x28 vector. Gave a lower loss then general 2D single channel image.\n",
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "    return x.view(-1, 1, 28, 28)\n",
        "\n",
        "# Accuracy check from Validation Test.\n",
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eSN4xwSlH3"
      },
      "source": [
        "### Initial Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XzHWMwESqht"
      },
      "source": [
        "bs = 64  # batch size\n",
        "lr = 0.1  # learning rate\n",
        "epochs = 2  # how many epochs to train for\n",
        "a = np.zeros((20, 10), dtype=(float,5))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmjbN1m4Hes_"
      },
      "source": [
        "### Training and Validation Datasets/DataLoaders \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtFZG5JNPmZ1"
      },
      "source": [
        "train_ds = TensorDataset(x_train, y_train)\n",
        "valid_ds = TensorDataset(x_valid, y_valid)\n",
        "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb_1kpsPQVeu"
      },
      "source": [
        "### Model and Optim (Use to do Foward Step)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_2xEVWOPfXY"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    Lambda(preprocess),\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AvgPool2d(4),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
        ")\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zlVNqLRQzrX"
      },
      "source": [
        "### Training of Model. Outputs Validation Loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90d4ijwtQ7Qu",
        "outputId": "d4668a11-a02d-4e0a-e19a-74d061a0d393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.32844958235025407 0.903184335443038\n",
            "1 0.2222142488002777 0.9346321202531646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VtIxe6hx_q_"
      },
      "source": [
        "### Testing different learning rate and momentum values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q55lEp7YyRmF",
        "outputId": "0ef497d9-47fc-4e52-9d8a-23bd88a04429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl, mat, lr, momentum):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            loss_batch(model, loss_func, xb, yb, opt)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "            )\n",
        "\n",
        "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "        val_acc = sum(accuracy(model(xb), yb) for xb, yb in valid_dl)    #valid_loss / len(valid_dl)\n",
        "        val_acc = val_acc.numpy() / len(valid_dl)\n",
        "        mat_data = (epoch, lr, momentum, val_loss, val_acc)\n",
        "        mat[int(((lr*20)-2)+epoch)][int(momentum*10)] = mat_data\n",
        "        print(epoch, val_loss, val_acc)\n",
        "    return mat\n",
        "################################################################################\n",
        "model = nn.Sequential(\n",
        "    Lambda(preprocess),\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AvgPool2d(4),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
        ")\n",
        "for x in range(10):           # Varying for LR from 0.1 to 1.0  \n",
        "  lr = (x+1)/10\n",
        "  for y in range(10):         # Varying for Momentum 0.0 to 0.9\n",
        "    momentum = y/10\n",
        "    opt = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "    print(lr, momentum)\n",
        "    a = fit(epochs, model, loss_func, opt, train_dl, valid_dl, a, lr, momentum)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1 0.0\n",
            "0 1.3558262022018432 0.5522151898734177\n",
            "1 0.8818770881652832 0.7006526898734177\n",
            "0.1 0.1\n",
            "0 0.507491164112091 0.8535403481012658\n",
            "1 0.4231681248188019 0.8794501582278481\n",
            "0.1 0.2\n",
            "0 0.4765414839506149 0.8577927215189873\n",
            "1 0.3212484186410904 0.9073378164556962\n",
            "0.1 0.3\n",
            "0 0.32180574489831926 0.8998219936708861\n",
            "1 0.2865055351018906 0.9149525316455697\n",
            "0.1 0.4\n",
            "0 0.2334865667939186 0.9348299050632911\n",
            "1 0.22433320047855376 0.9340387658227848\n",
            "0.1 0.5\n",
            "0 0.325609538435936 0.9042721518987342\n",
            "1 0.23776539866924287 0.9268196202531646\n",
            "0.1 0.6\n",
            "0 0.19740060652196406 0.9406645569620253\n",
            "1 0.2151036279141903 0.9362143987341772\n",
            "0.1 0.7\n",
            "0 0.20004336276352405 0.942246835443038\n",
            "1 0.20228782544732093 0.9408623417721519\n",
            "0.1 0.8\n",
            "0 0.17519655836820602 0.9482792721518988\n",
            "1 0.17256289960294963 0.9496637658227848\n",
            "0.1 0.9\n",
            "0 0.20380617601275444 0.935126582278481\n",
            "1 0.15065279561281203 0.9550039556962026\n",
            "0.2 0.0\n",
            "0 0.14262626667022704 0.9608386075949367\n",
            "1 0.11378676705956459 0.9658821202531646\n",
            "0.2 0.1\n",
            "0 0.11666894634366036 0.9655854430379747\n",
            "1 0.11282083710730076 0.9664754746835443\n",
            "0.2 0.2\n",
            "0 0.1147856478869915 0.966376582278481\n",
            "1 0.10997723387479783 0.9674643987341772\n",
            "0.2 0.3\n",
            "0 0.12043592512607575 0.9657832278481012\n",
            "1 0.11194584164321422 0.9666732594936709\n",
            "0.2 0.4\n",
            "0 0.11614582560062409 0.9652887658227848\n",
            "1 0.1505134506314993 0.955498417721519\n",
            "0.2 0.5\n",
            "0 0.11961580140590668 0.9672666139240507\n",
            "1 0.11956305202245712 0.965684335443038\n",
            "0.2 0.6\n",
            "0 0.10823083936274051 0.9681566455696202\n",
            "1 0.14040930334329604 0.9597507911392406\n",
            "0.2 0.7\n",
            "0 0.1278979041159153 0.9629153481012658\n",
            "1 0.11407392633855343 0.9672666139240507\n",
            "0.2 0.8\n",
            "0 0.14799430397152902 0.9571795886075949\n",
            "1 0.11848335780203342 0.9659810126582279\n",
            "0.2 0.9\n",
            "0 0.12939949619472027 0.9622231012658228\n",
            "1 0.13573413135409354 0.964003164556962\n",
            "0.3 0.0\n",
            "0 0.10006030628979207 0.9699367088607594\n",
            "1 0.09154373431652785 0.9739912974683544\n",
            "0.3 0.1\n",
            "0 0.0945066893428564 0.974189082278481\n",
            "1 0.09917772351503372 0.9721123417721519\n",
            "0.3 0.2\n",
            "0 0.0931254169255495 0.9744857594936709\n",
            "1 0.09102429595887661 0.9745846518987342\n",
            "0.3 0.3\n",
            "0 0.18428781105279923 0.9473892405063291\n",
            "1 0.11177314583212138 0.967068829113924\n",
            "0.3 0.4\n",
            "0 0.09180274505726993 0.9732990506329114\n",
            "1 0.09179643409103155 0.9742879746835443\n",
            "0.3 0.5\n",
            "0 0.09807749391719699 0.9724090189873418\n",
            "1 0.09304641031324863 0.9744857594936709\n",
            "0.3 0.6\n",
            "0 0.10660730886310339 0.9698378164556962\n",
            "1 0.10294083197824656 0.9722112341772152\n",
            "0.3 0.7\n",
            "0 0.21402257984876633 0.9373022151898734\n",
            "1 0.10370233527868986 0.9709256329113924\n",
            "0.3 0.8\n",
            "0 0.11257954482138156 0.9691455696202531\n",
            "1 0.1353478933095932 0.9613330696202531\n",
            "0.3 0.9\n",
            "0 0.15317453415989876 0.9565862341772152\n",
            "1 0.17340967957675457 0.9486748417721519\n",
            "0.4 0.0\n",
            "0 0.14156013404726983 0.960245253164557\n",
            "1 0.09105618464350701 0.9746835443037974\n",
            "0.4 0.1\n",
            "0 0.09424170682951807 0.9742879746835443\n",
            "1 0.09326461362987756 0.9750791139240507\n",
            "0.4 0.2\n",
            "0 0.09082450689617544 0.9751780063291139\n",
            "1 0.09257108582518994 0.9754746835443038\n",
            "0.4 0.3\n",
            "0 0.09641581102963537 0.9737935126582279\n",
            "1 0.09317804353162647 0.9751780063291139\n",
            "0.4 0.4\n",
            "0 0.09709678393267095 0.9739912974683544\n",
            "1 0.09756097006220371 0.9754746835443038\n",
            "0.4 0.5\n",
            "0 0.1035334438636899 0.9713212025316456\n",
            "1 0.09971877614408732 0.9743868670886076\n",
            "0.4 0.6\n",
            "0 0.10634204992577434 0.9720134493670886\n",
            "1 0.10271488598845899 0.9742879746835443\n",
            "0.4 0.7\n",
            "0 0.14117679494321347 0.9628164556962026\n",
            "1 0.10283489251472056 0.9698378164556962\n",
            "0.4 0.8\n",
            "0 0.13188608057834209 0.9662776898734177\n",
            "1 0.1606811507191509 0.9601463607594937\n",
            "0.4 0.9\n",
            "0 0.18887332669198514 0.9510482594936709\n",
            "1 0.1551114939659834 0.9580696202531646\n",
            "0.5 0.0\n",
            "0 0.10444803060889245 0.9720134493670886\n",
            "1 0.09720433875471353 0.974189082278481\n",
            "0.5 0.1\n",
            "0 0.09430531410872936 0.9740901898734177\n",
            "1 0.09727860351242125 0.9729034810126582\n",
            "0.5 0.2\n",
            "0 0.0964976942062378 0.9745846518987342\n",
            "1 0.09795039839595557 0.974881329113924\n",
            "0.5 0.3\n",
            "0 0.09384099533408881 0.9739912974683544\n",
            "1 0.10308129654824734 0.973496835443038\n",
            "0.5 0.4\n",
            "0 0.09500714137107134 0.9760680379746836\n",
            "1 0.10112621031738818 0.974881329113924\n",
            "0.5 0.5\n",
            "0 0.11401659566313029 0.9703322784810127\n",
            "1 0.1033542487718165 0.9732001582278481\n",
            "0.5 0.6\n",
            "0 0.11174216966554522 0.9712223101265823\n",
            "1 0.11777583467066288 0.9693433544303798\n",
            "0.5 0.7\n",
            "0 0.11767529476583004 0.969442246835443\n",
            "1 0.12004100167900324 0.9686511075949367\n",
            "0.5 0.8\n",
            "0 0.14249918775856496 0.961629746835443\n",
            "1 0.17291475908756257 0.9534216772151899\n",
            "0.5 0.9\n",
            "0 0.18548613780736922 0.9477848101265823\n",
            "1 0.2092354319959879 0.9452136075949367\n",
            "0.6 0.0\n",
            "0 0.10642246292904019 0.9705300632911392\n",
            "1 0.10156532351896166 0.9728045886075949\n",
            "0.6 0.1\n",
            "0 0.1008234338670969 0.9712223101265823\n",
            "1 0.10083081419169902 0.9719145569620253\n",
            "0.6 0.2\n",
            "0 0.10294132359102369 0.9717167721518988\n",
            "1 0.09943292960487306 0.9735957278481012\n",
            "0.6 0.3\n",
            "0 0.1008645635932684 0.9720134493670886\n",
            "1 0.10135874770209194 0.9736946202531646\n",
            "0.6 0.4\n",
            "0 0.11100664654970169 0.9669699367088608\n",
            "1 0.10080661787688733 0.9735957278481012\n",
            "0.6 0.5\n",
            "0 0.10541323553584515 0.9735957278481012\n",
            "1 0.11381033531837165 0.9707278481012658\n",
            "0.6 0.6\n",
            "0 0.10645225392878055 0.9725079113924051\n",
            "1 0.1059981828942895 0.9715189873417721\n",
            "0.6 0.7\n",
            "0 0.10838101866841317 0.9703322784810127\n",
            "1 0.10659628263115883 0.971815664556962\n",
            "0.6 0.8\n",
            "0 0.1526953205384314 0.9593552215189873\n",
            "1 0.14291589144468309 0.9562895569620253\n",
            "0.6 0.9\n",
            "0 0.3288565555751324 0.9088212025316456\n",
            "1 0.21585312623977662 0.938192246835443\n",
            "0.7 0.0\n",
            "0 0.11735067487657071 0.966376582278481\n",
            "1 0.11777090787887573 0.9677610759493671\n",
            "0.7 0.1\n",
            "0 0.1088528175458312 0.9712223101265823\n",
            "1 0.10491086727678776 0.9727056962025317\n",
            "0.7 0.2\n",
            "0 0.10671177990585566 0.9719145569620253\n",
            "1 0.11054789071902632 0.9707278481012658\n",
            "0.7 0.3\n",
            "0 0.11100872326865792 0.9710245253164557\n",
            "1 0.10657808107286691 0.9719145569620253\n",
            "0.7 0.4\n",
            "0 0.10492132800519466 0.9722112341772152\n",
            "1 0.10430008117742837 0.973496835443038\n",
            "0.7 0.5\n",
            "0 0.10639137369692325 0.971815664556962\n",
            "1 0.10646257556304335 0.9726068037974683\n",
            "0.7 0.6\n",
            "0 0.12661431614756585 0.9621242088607594\n",
            "1 0.11973037233836949 0.9689477848101266\n",
            "0.7 0.7\n",
            "0 0.14835257951915265 0.957871835443038\n",
            "1 0.11972851440235972 0.9695411392405063\n",
            "0.7 0.8\n",
            "0 0.14991178602576255 0.958564082278481\n",
            "1 0.133282907012105 0.9648931962025317\n",
            "0.7 0.9\n",
            "0 0.46013506054878234 0.8715387658227848\n",
            "1 0.2590962275803089 0.9224683544303798\n",
            "0.8 0.0\n",
            "0 0.16066823460161686 0.9526305379746836\n",
            "1 0.1447379349440336 0.9570806962025317\n",
            "0.8 0.1\n",
            "0 0.13084574683904648 0.9600474683544303\n",
            "1 0.12992607276290655 0.9634098101265823\n",
            "0.8 0.2\n",
            "0 0.1313598060786724 0.9619264240506329\n",
            "1 0.16696364010870457 0.9529272151898734\n",
            "0.8 0.3\n",
            "0 0.19608686092197894 0.9464003164556962\n",
            "1 0.15848806992918252 0.956190664556962\n",
            "0.8 0.4\n",
            "0 0.20259164662361145 0.9471914556962026\n",
            "1 0.15372405680418014 0.954806170886076\n",
            "0.8 0.5\n",
            "0 0.14771150071620942 0.9579707278481012\n",
            "1 0.15097424504607915 0.9566851265822784\n",
            "0.8 0.6\n",
            "0 0.23938075420856475 0.935818829113924\n",
            "1 0.15920238967090844 0.9544106012658228\n",
            "0.8 0.7\n",
            "0 0.16976130564808845 0.9494659810126582\n",
            "1 0.1625918599292636 0.9522349683544303\n",
            "0.8 0.8\n",
            "0 0.29633866468667985 0.9117879746835443\n",
            "1 0.2633338034629822 0.9257318037974683\n",
            "0.8 0.9\n",
            "0 1.704014385032654 0.42167721518987344\n",
            "1 1.6607231861114502 0.4482792721518987\n",
            "0.9 0.0\n",
            "0 1.6186063335418701 0.46795886075949367\n",
            "1 1.6093615118026734 0.4639042721518987\n",
            "0.9 0.1\n",
            "0 1.5641193521499634 0.4911985759493671\n",
            "1 1.468985097503662 0.5083069620253164\n",
            "0.9 0.2\n",
            "0 1.4437558336257934 0.5157238924050633\n",
            "1 1.4411825038909911 0.512559335443038\n",
            "0.9 0.3\n",
            "0 1.4411187696456909 0.5216574367088608\n",
            "1 1.3432006395339966 0.5490506329113924\n",
            "0.9 0.4\n",
            "0 1.345744192123413 0.5473694620253164\n",
            "1 1.3573628057479858 0.5534018987341772\n",
            "0.9 0.5\n",
            "0 1.2857106672286986 0.5708069620253164\n",
            "1 1.2781818548202515 0.575059335443038\n",
            "0.9 0.6\n",
            "0 1.261348496246338 0.577432753164557\n",
            "1 1.2565855400085448 0.5865308544303798\n",
            "0.9 0.7\n",
            "0 1.2159356868743896 0.6132318037974683\n",
            "1 1.1487042139053345 0.6190664556962026\n",
            "0.9 0.8\n",
            "0 1.0435512189865113 0.6577333860759493\n",
            "1 1.0730277084350586 0.6614912974683544\n",
            "0.9 0.9\n",
            "0 1.234960631752014 0.6123417721518988\n",
            "1 1.179074691772461 0.6246044303797469\n",
            "1.0 0.0\n",
            "0 0.8961756907463073 0.7105419303797469\n",
            "1 0.8635112216949463 0.7198378164556962\n",
            "1.0 0.1\n",
            "0 1.2130308435440063 0.6071004746835443\n",
            "1 0.8418956979751587 0.7275514240506329\n",
            "1.0 0.2\n",
            "0 0.8327745497703553 0.7300237341772152\n",
            "1 0.8413625648498535 0.7305181962025317\n",
            "1.0 0.3\n",
            "0 0.8969934484481812 0.7143987341772152\n",
            "1 0.9155545302391053 0.7082674050632911\n",
            "1.0 0.4\n",
            "0 0.8430174870491027 0.7387262658227848\n",
            "1 2.3025827449798584 0.09642009493670886\n",
            "1.0 0.5\n",
            "0 2.3025827449798584 0.09642009493670886\n",
            "1 2.3025827449798584 0.09642009493670886\n",
            "1.0 0.6\n",
            "0 2.3025827449798584 0.09642009493670886\n",
            "1 2.3025827449798584 0.09642009493670886\n",
            "1.0 0.7\n",
            "0 2.3025827449798584 0.09642009493670886\n",
            "1 2.3025827449798584 0.09642009493670886\n",
            "1.0 0.8\n",
            "0 2.3025827449798584 0.09642009493670886\n",
            "1 2.3025827449798584 0.09642009493670886\n",
            "1.0 0.9\n",
            "0 2.3025827449798584 0.09642009493670886\n",
            "1 2.3025827449798584 0.09642009493670886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rtgLEiyDVYv"
      },
      "source": [
        "### Graphical Illustration of Accuracy for Varying Values of Learning Rate and Momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9MnQ3BL9kAu"
      },
      "source": [
        "def Largest_Moment(mat, index):\n",
        "  best_Momentum_index = 0;\n",
        "  for x in range(10):\n",
        "    if(mat[index][x][4] > mat[index][best_Momentum_index][4]):\n",
        "      best_Momentum_index = x\n",
        "  return best_Momentum_index\n",
        "\n",
        "mat_lr = np.zeros(20)\n",
        "mat_moment = np.zeros(20)\n",
        "mat_acc = np.zeros(20)\n",
        "\n",
        "for i in range(20):\n",
        "  mat_lr[i] = a[i][0][1]\n",
        "  # Momentum index with greatest Accuracy of a given LR.\n",
        "  large = Largest_Moment(a, i)\n",
        "  mat_moment[i] = a[i][large][2]\n",
        "  mat_acc[i] = a[i][large][4]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k6Tg4YjMgNw"
      },
      "source": [
        "The arrays of LR, Momentum, and Accuracy should be counted in groups of 2. First Value is epoch 1, second value is epoch 2. Then LR/Momentum will increment. For example, below we see that the 8th value in accuracy array is the largest. This corresponds to a learning rate of 0.5 and momentum 0.4 and epoch 1. Loss of valiation sets are also shown as 0.9500714. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGDJF_IWMBWk",
        "outputId": "6889cd8c-3a49-4082-fc3d-bc043584866e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "print(mat_acc)\n",
        "print(mat_moment[8])\n",
        "print(a[8][4])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.94827927 0.95500396 0.96815665 0.9674644  0.97448576 0.97458465\n",
            " 0.97517801 0.97547468 0.97606804 0.97488133 0.97359573 0.97369462\n",
            " 0.97221123 0.97349684 0.96192642 0.96340981 0.65773339 0.6614913\n",
            " 0.73872627 0.7305182 ]\n",
            "0.4\n",
            "[0.         0.5        0.4        0.09500714 0.97606804]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYtsstdMJF1u",
        "outputId": "2cbe62d3-2b8b-4735-cd13-f00c9908c2aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "fig, ax = pyplot.subplots()\n",
        "ax.plot(mat_lr, mat_moment, 'ro')\n",
        "ax.axis([0, 1, 0, 1])\n",
        "ax.set(xlabel='Learning Rate', ylabel='Momentum Value with Largest Accuracy')\n",
        "ax.grid()\n",
        "pyplot.show()\n",
        "\n",
        "fig, ax = pyplot.subplots()\n",
        "ax.plot(mat_lr, mat_acc, 'ro')\n",
        "ax.axis([0, 1, 0, 1])\n",
        "ax.set(xlabel='Learning Rate', ylabel='Accuracy')\n",
        "ax.grid()\n",
        "pyplot.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWLElEQVR4nO3df7BndX3f8eeL/RFcIZqR1Vp+LGhhlZoqShG11Ws0LVhdbG0SmHWMlWEjWy1WS2OH1lASZprYaNSCejMFGmcV0TTONqJkonuDNWKBolRQzIqLLNpBCKIrkXWXd/84Z/v9ct0993vv3nO/3737fMzcud9zvp/v+b7ve/bu657z+Z5zUlVIknQgR4y7AEnSZDMoJEmdDApJUieDQpLUyaCQJHUyKCRJnXoLiiRXJbk/ydcO8HySvD/J9iS3J3l+X7VIkhauzz2Ka4CzOp4/Gzi5/doEfLDHWiRJC9RbUFTVjcBfdww5B/ijatwEPDnJ0/uqR5K0MCvH+N7HAvcOLe9s131v9sAkm2j2OjjyyCNfcMIJJyxJgZPuscce44gjnGYCezHMXgzYi4FvfvObD1TV2oW8dpxBMbKqmgamAdavX1933XXXmCuaDDMzM0xNTY27jIlgLwbsxYC9GEhyz0JfO86ovQ84fmj5uHadJGmCjDMotgJvaD/9dCbwcFX9zGEnTbDNm2HlSkia75s3j62Gl7385WOvYax9GKrDXmjRVVUvX8DHaOYbfkoz/3A+8Gbgze3zAa4AvgX8H+D0UbZ7yimn1GHvwgurVqyox6BqxYpmeRw1wM9+LWUt1jBZdUxCDbNs27ZtbO89aYBbaoH/n6cOscuMH/ZzFJs3wwf380niCy+EK69cujpWroS9e392/YoVsGePNSxlDZNSxyTUsM+WLXDJJdR3vkNOOAEuvxw2blzaGiZMklur6vQFvdagOMRMyi9jcuDnlurflDVMVh2TUAM0IfGmN8Hu3YN1q1fDVVcd1mFxMEHh58bma8sWOPFEOOKI5vuWLUv7/vsLia71fVmxYn7rrWH51zEJNQBcdNHjQwKa5YsuWto6lhGDYj62bIFNm+Cee5q/kO65p1leyrCYlF/GTZvmt94aln8dk1ADwIMPzm+95rbQyY1xfY11Mnvduv1P1q1bt3Q1TNKEYTupXuOeVJ+Eif1x92GojsO+F/v7/dj3dRjDyewlMinHYDdvhulpau9esmJF8xfbUk5kTyBPrBo47HtxzDH733t4ylPggQeWvp4J4RzFUpmUwz5XXgl79vAX27Y1E9iHeUhIj/O+98GqVY9ft2pVs14LYlDMx6RMJEs6sI0b4eqrYd06KoF165rlw/gTTwfLoJiPdevmt17SeGzcCDt28Bef/zzs2GFIHCSDYj4uvxzWrHn8ujVrmvWStEwZFPOxcSNMTzd7EPt2aaen/WtF0rJ2SFxmfKJs3GgwSDqsuEchSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpU69BkeSsJHcl2Z7knft5/oQk25LcluT2JK/qsx5J0vz1FhRJVgBXAGcDpwLnJTl11rB/D1xXVacB5wJX9lWPJGlh+tyjOAPYXlV3V9Vu4FrgnFljCvj59vGTgO/2WI8kaQFW9rjtY4F7h5Z3Ai+cNeZS4M+SvBV4IvDK/W0oySZgE8DatWuZmZlZ7FoPSbt27bIXLXsxYC8G7MXi6DMoRnEecE1V/X6SFwEfSfKcqnpseFBVTQPTAOvXr6+pqamlr3QCzczMYC8a9mLAXgzYi8XR56Gn+4Djh5aPa9cNOx+4DqCqvgQcCRzTY02SpHnqMyhuBk5OclKS1TST1VtnjfkO8AqAJM+mCYrv91iTJGmeeguKqtoDvAW4Afg6zaeb7khyWZIN7bB3ABck+SrwMeCNVVV91SRJmr9e5yiq6nrg+lnr3jX0+E7gJX3WIEk6OJ6ZLUnqZFBIkjoZFJKkTgaFJKmTQSFJy9mWLXDiibwAXrDQTYz7zGxJUl+2bIFNm+CRRw5qM+5RSNJydcklBx0SYFBI0vJ1zz2LshmDQpKWqxUrFmUzBoUkLVd79y7KZgwKSVqu1q1blM0YFJK0XF1+OaxZc9CbMSgkabnauBGmpw96z8KgkKTlbONG2LGDW+HWhW7CoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS+tDeMIgjjmi+b9ky7ooWzBsXSdJi27IF3vQm2L27Wb7nnmYZmhPgDjHuUUjSYrvookFI7LN7d7P+EGRQSNJie/DB+a2fcAaFJKmTQSFJi+0pT5nf+glnUEjSYnvf+2DVqsevW7WqWX8IMigkabFt3AhXX93cByJpvl999SH5iSfw47GS1I+NGw/ZYJjNPQpJUieDQpLUyaCQJHUyKCRJnXoNiiRnJbkryfYk7zzAmF9NcmeSO5J8tM96JEnz19unnpKsAK4AfhnYCdycZGtV3Tk05mTg3wEvqaqHkjy1r3okSQvT5x7FGcD2qrq7qnYD1wLnzBpzAXBFVT0EUFX391iPJGkB+jyP4ljg3qHlncALZ405BSDJF4EVwKVV9dnZG0qyCdgEsHbtWmZmZvqo95Cza9cue9GyFwP2YsBeLI5xn3C3EjgZmAKOA25M8otV9YPhQVU1DUwDrF+/vqamppa4zMk0MzODvWjYiwF7MWAvFsech56SvCbJQg5R3QccP7R8XLtu2E5ga1X9tKq+DXyTJjgkSRNilAD4NeCvkvxekmfNY9s3AycnOSnJauBcYOusMZ+i2ZsgyTE0h6Lunsd7SJJ6NmdQVNXrgdOAbwHXJPlSkk1Jjp7jdXuAtwA3AF8HrquqO5JclmRDO+wG4MEkdwLbgIur6tC8s4ckLVMjzVFU1Q+TfBJ4AvA24J8CFyd5f1V9oON11wPXz1r3rqHHBby9/ZIkTaBR5ig2JPkTYAZYBZxRVWcDzwXe0W95kqRxG2WP4nXAe6vqxuGVVfVIkvP7KUuSNClGCYpLge/tW0jyBOBpVbWjqj7XV2GSpMkwyqeePgE8NrS8t10nSToMjBIUK9tLcADQPl7dX0mSpEkySlB8f+jjrCQ5B3igv5IkSZNklDmKNwNbkvwXIDTXb3pDr1VJkibGnEFRVd8CzkxyVLu8q/eqJEkTY6QT7pL8E+DvAkcmAaCqLuuxLknShBjlhLsP0Vzv6a00h55+BVjXc12SpAkxymT2i6vqDcBDVfUfgRfR3kdCkrT8jRIUP2m/P5LkbwM/BZ7eX0mSpEkyyhzF/0jyZODdwP8GCvjDXquSJE2MzqBob1j0ufaOc3+c5E+BI6vq4SWpTpI0dp2HnqrqMeCKoeVHDQlJOryMMkfxuSSvy77PxUqSDiujBMVv0FwE8NEkP0zyoyQ/7LkuSdKEGOXM7M5bnkqSlrc5gyLJS/e3fvaNjCRJy9MoH4+9eOjxkcAZwK3AL/VSkSRpooxy6Ok1w8tJjgf+oLeKJEkTZZTJ7Nl2As9e7EIkSZNplDmKD9CcjQ1NsDyP5gxtSdJhYJQ5iluGHu8BPlZVX+ypHknShBklKD4J/KSq9gIkWZFkTVU90m9pkqRJMNKZ2cAThpafAPx5P+VIkibNKEFx5PDtT9vHa/orSZI0SUYJih8nef6+hSQvAP6mv5IkSZNklDmKtwGfSPJdmluh/i2aW6NKkg4Do5xwd3OSZwHr21V3VdVP+y1LkjQp5jz0lORfAk+sqq9V1deAo5Js7r80SdIkGGWO4oL2DncAVNVDwAX9lSRJmiSjBMWK4ZsWJVkBrO6vJEnSJBllMvuzwMeTfLhd/g3gM/2VJEmaJKMExW8Cm4A3t8u303zySZJ0GJjz0FNVPQZ8GdhBcy+KXwK+PsrGk5yV5K4k25O8s2Pc65JUktNHK1uStFQOuEeR5BTgvPbrAeDjAFX18lE23M5lXAH8Ms2lyW9OsrWq7pw17mjgIpowkiRNmK49im/Q7D28uqr+QVV9ANg7j22fAWyvqrurajdwLXDOfsb9NvC7wE/msW1J0hLpmqP4Z8C5wLYkn6X5jz4d42c7Frh3aHkn8MLhAe2lQY6vqk8nGb7lKrPGbaKZJ2Ht2rXMzMzMo4zla9euXfaiZS8G7MWAvVgcBwyKqvoU8KkkT6TZE3gb8NQkHwT+pKr+7GDeOMkRwHuAN841tqqmgWmA9evX19TU1MG89bIxMzODvWjYiwF7MWAvFscok9k/rqqPtvfOPg64jeaTUHO5Dzh+aPm4dt0+RwPPAWaS7ADOBLY6oS1Jk2Ve98yuqoeqarqqXjHC8JuBk5OclGQ1zWGsrUPberiqjqmqE6vqROAmYENV3bL/zUmSxmFeQTEfVbUHeAtwA83Haa+rqjuSXJZkQ1/vK0laXKOccLdgVXU9cP2sde86wNipPmuRJC1Mb3sUkqTlwaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdeo1KJKcleSuJNuTvHM/z789yZ1Jbk/yuSTr+qxHkjR/vQVFkhXAFcDZwKnAeUlOnTXsNuD0qvp7wCeB3+urHknSwvS5R3EGsL2q7q6q3cC1wDnDA6pqW1U90i7eBBzXYz2SpAVY2eO2jwXuHVreCbywY/z5wGf290SSTcAmgLVr1zIzM7NIJR7adu3aZS9a9mLAXgzYi8XRZ1CMLMnrgdOBl+3v+aqaBqYB1q9fX1NTU0tX3ASbmZnBXjTsxYC9GLAXi6PPoLgPOH5o+bh23eMkeSVwCfCyqnq0x3okSQvQ5xzFzcDJSU5Ksho4F9g6PCDJacCHgQ1VdX+PtUiSFqi3oKiqPcBbgBuArwPXVdUdSS5LsqEd9m7gKOATSb6SZOsBNidJGpNe5yiq6nrg+lnr3jX0+JV9vr8k6eB5ZrYkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOvUaFEnOSnJXku1J3rmf538uycfb57+c5MQ+65EkzV9vQZFkBXAFcDZwKnBeklNnDTsfeKiq/g7wXuB3+6pHkrQwfe5RnAFsr6q7q2o3cC1wzqwx5wD/rX38SeAVSdJjTZKkeVrZ47aPBe4dWt4JvPBAY6pqT5KHgacADwwPSrIJ2NQuPprka71UfOg5hlm9OozZiwF7MWAvBtYv9IV9BsWiqappYBogyS1VdfqYS5oI9mLAXgzYiwF7MZDkloW+ts9DT/cBxw8tH9eu2++YJCuBJwEP9liTJGme+gyKm4GTk5yUZDVwLrB11pitwK+3j/858Pmqqh5rkiTNU2+Hnto5h7cANwArgKuq6o4klwG3VNVW4L8CH0myHfhrmjCZy3RfNR+C7MWAvRiwFwP2YmDBvYh/wEuSunhmtiSpk0EhSeo0sUHh5T8GRujF25PcmeT2JJ9Lsm4cdS6FuXoxNO51SSrJsv1o5Ci9SPKr7b+NO5J8dKlrXCoj/I6ckGRbktva35NXjaPOviW5Ksn9BzrXLI33t326PcnzR9pwVU3cF83k97eAZwCrga8Cp84asxn4UPv4XODj4657jL14ObCmfXzh4dyLdtzRwI3ATcDp4657jP8uTgZuA36hXX7quOseYy+mgQvbx6cCO8Zdd0+9eCnwfOBrB3j+VcBngABnAl8eZbuTukfh5T8G5uxFVW2rqkfaxZtozllZjkb5dwHw2zTXDfvJUha3xEbpxQXAFVX1EEBV3b/ENS6VUXpRwM+3j58EfHcJ61syVXUjzSdID+Qc4I+qcRPw5CRPn2u7kxoU+7v8x7EHGlNVe4B9l/9YbkbpxbDzaf5iWI7m7EW7K318VX16KQsbg1H+XZwCnJLki0luSnLWklW3tEbpxaXA65PsBK4H3ro0pU2c+f5/Ahwil/DQaJK8HjgdeNm4axmHJEcA7wHeOOZSJsVKmsNPUzR7mTcm+cWq+sFYqxqP84Brqur3k7yI5vyt51TVY+Mu7FAwqXsUXv5jYJRekOSVwCXAhqp6dIlqW2pz9eJo4DnATJIdNMdgty7TCe1R/l3sBLZW1U+r6tvAN2mCY7kZpRfnA9cBVNWXgCNpLhh4uBnp/5PZJjUovPzHwJy9SHIa8GGakFiux6Fhjl5U1cNVdUxVnVhVJ9LM12yoqgVfDG2CjfI78imavQmSHENzKOrupSxyiYzSi+8ArwBI8myaoPj+klY5GbYCb2g//XQm8HBVfW+uF03koafq7/Ifh5wRe/Fu4CjgE+18/neqasPYiu7JiL04LIzYixuAf5TkTmAvcHFVLbu97hF78Q7gD5P8a5qJ7Tcuxz8sk3yM5o+DY9r5mN8CVgFU1Ydo5mdeBWwHHgH+xUjbXYa9kiQtokk99CRJmhAGhSSpk0EhSepkUEiSOhkUkqROBoWWhSS7lvj9/nKRtjOV5OEkX0nyjST/eYTXvDbJqYvx/tIoDAppP9qz/Q+oql68iG/3hap6HnAa8OokL5lj/GtproAqLQmDQstWkmcm+WySW5N8Icmz2vWvae9hcluSP0/ytHb9pUk+kuSLNCdzXtpe338myd1J/tXQtne136fa5z/Z7hFs2XcV4ySvatfd2t4D4E+76q2qvwG+QnuRtiQXJLk5yVeT/HGSNUleDGwA3t3uhTzzQD+ntFgMCi1n08Bbq+oFwL8BrmzX/0/gzKo6jeaS1P926DWnAq+sqvPa5WcB/5jmUta/lWTVft7nNOBt7WufAbwkyZE0l1U5u33/tXMVm+QXaK7FdGO76r9X1d+vqucCXwfOr6q/pLkMw8VV9byq+lbHzyktiom8hId0sJIcBbyYwWVNAH6u/X4c8PH2OvyrgW8PvXRr+5f9Pp9uL7L4aJL7gafRXGxv2P+qqp3t+34FOBHYBdzdXowP4GPApgOU+w+TfJUmJP6gqv5vu/45SX4HeDLNJVpumOfPKS0Kg0LL1RHAD9pj/7N9AHhPVW1NMkVzr4J9fjxr7PCVePey/9+ZUcZ0+UJVvTrJScBNSa6rqq8A1wCvraqvJnkj7QX+Zun6OaVF4aEnLUtV9UPg20l+Bf7/vYKf2z79JAaXVv71/b1+EdwFPCODe7n/2lwvaPc+/hPwm+2qo4HvtYe7Ng4N/VH73Fw/p7QoDAotF2uS7Bz6ejvNf67nt4d17mBwe8xLaQ7V3Ao80Ecx7eGrzcBn2/f5Ec1dGOfyIeClbcD8B+DLwBeBbwyNuRa4uJ2MfyYH/jmlReHVY6WeJDmqqna1n4K6AvirqnrvuOuS5ss9Cqk/F7ST23fQHO768JjrkRbEPQpJUif3KCRJnQwKSVIng0KS1MmgkCR1MigkSZ3+HxMq42A/WqYWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6-MGTB7Jr58"
      },
      "source": [
        "From the plot above. We got our best accuracy, 0.97606804, with a learning rate of 0.5 and a momentum of 0.4. In the graphs above, every LR has two dots since there is 2 epochs."
      ]
    }
  ]
}