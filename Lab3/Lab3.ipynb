{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "import wget\n",
    "\n",
    "\n",
    "def collect_pdfs():\n",
    "    base_url = 'http://proceedings.mlr.press/v70/'\n",
    "    html = urlopen(base_url).read()\n",
    "    html_page = bs(html) \n",
    "    \n",
    "    collected = []\n",
    "    \n",
    "    for link in html_page.find_all('a'):\n",
    "        if link.get('href').endswith('pdf'):\n",
    "            try:\n",
    "                filename = './pdfs/' + link.get('href').split('/')[-1]\n",
    "                wget.download(link.get('href'), out=filename)\n",
    "                collected.append(filename)\n",
    "            except:\n",
    "                print('Could not download ', link.get('href'))\n",
    "    \n",
    "    return collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "def pdf_to_text(filename):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    with open(filename, 'rb') as pdf:\n",
    "        for page in PDFPage.get_pages(pdf):\n",
    "            interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not download  http://proceedings.mlr.press/v70/arık17a/arık17a-supp.pdf\n"
     ]
    }
   ],
   "source": [
    "files = collect_pdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out all the pdf content into a text file\n",
    "# avoids having to do this multiple times\n",
    "    \n",
    "with open('training_words.txt', 'w') as txt_file:\n",
    "    for pdf in files:\n",
    "        text = pdf_to_text(pdf)\n",
    "        txt_file.write(text)\n",
    "        txt_file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "training_words = None\n",
    "\n",
    "with open('training_words.txt', 'r') as train:\n",
    "    training_words = train.read()\n",
    "\n",
    "c = Counter([x.lower() for x in training_words.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {k:v for k, v in sorted(c.items(), key=lambda x: x[1], reverse=True) if k.isalpha() and len(k) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 205147, 'of': 101886, 'and': 87289, 'in': 68292, 'to': 64706, 'is': 55298, 'for': 51197, 'we': 50972, 'that': 36466, 'with': 29882}\n"
     ]
    }
   ],
   "source": [
    "top10 = dict(sorted(counts.items(), key=lambda x: x[1], reverse = True)[:10])\n",
    "print(top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.708366314011496\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_observed = sum(v for _,v in counts.items())\n",
    "entropy = 0\n",
    "for _, obs in counts.items():\n",
    "    entropy += (obs/total_observed) * np.log2(obs/total_observed)\n",
    "entropy = -entropy\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2643672\n",
      "in\n",
      "local\n",
      "zhang\n",
      "using\n",
      "jl\n",
      "two\n",
      "et\n",
      "sales\n",
      "here\n",
      "the\n",
      "take\n",
      "and\n",
      "is\n",
      "multiscale\n",
      "of\n",
      "for\n",
      "number\n",
      "decision\n",
      "was\n",
      "are\n",
      "et\n",
      "bringing\n",
      "royal\n",
      "ranges\n",
      "to\n",
      "the\n",
      "is\n",
      "of\n",
      "tried\n",
      "journal\n",
      "formal\n",
      "cab\n",
      "according\n",
      "with\n",
      "guaranteed\n",
      "from\n",
      "he\n",
      "can\n",
      "as\n",
      "and\n",
      "course\n",
      "literature\n",
      "axis\n",
      "with\n",
      "the\n",
      "the\n",
      "is\n",
      "structured\n",
      "to\n",
      "all\n",
      "exercise\n",
      "powerful\n",
      "miny\n",
      "evaluations\n",
      "chosen\n",
      "the\n",
      "maximization\n",
      "intervention\n",
      "set\n",
      "factorization\n",
      "our\n",
      "in\n",
      "iteration\n",
      "and\n",
      "the\n",
      "we\n",
      "changing\n",
      "result\n",
      "variational\n",
      "in\n",
      "and\n",
      "using\n",
      "on\n",
      "is\n",
      "and\n",
      "fourth\n",
      "an\n",
      "across\n",
      "the\n",
      "decision\n",
      "assumed\n",
      "using\n",
      "due\n",
      "baselines\n",
      "statement\n",
      "be\n",
      "rectangular\n",
      "spirit\n",
      "on\n",
      "in\n",
      "to\n",
      "the\n",
      "of\n",
      "saga\n",
      "it\n",
      "the\n",
      "introduction\n",
      "using\n",
      "clamping\n",
      "to\n"
     ]
    }
   ],
   "source": [
    "probabilities = []\n",
    "for word, obs in counts.items():\n",
    "    probabilities.extend([word] * obs)\n",
    "print(len(probabilities))\n",
    "\n",
    "for i in range(100):\n",
    "    num = np.random.uniform(0, total_observed)\n",
    "    print(probabilities[int(num)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "%matplotlib inline\n",
    "train = pd.read_csv('./kaggle/train.csv')\n",
    "test = pd.read_csv('./kaggle/test.csv')\n",
    "\n",
    "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition']))\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "prices = pd.DataFrame({\"price\":train[\"SalePrice\"], \"log(price + 1)\":np.log1p(train[\"SalePrice\"])})\n",
    "prices.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_feats = train.dtypes[train.dtypes != \"object\"].index\n",
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\n",
    "\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data)\n",
    "all_data = all_data.fillna(all_data.mean())\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = all_data[:train.shape[0]]\n",
    "X_test = all_data[train.shape[0]:]\n",
    "y = train.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_ridge = Ridge(alpha=0.1)\n",
    "model_ridge.fit(X_train, y)\n",
    "\n",
    "results = np.expm1(model_ridge.predict(X_test))\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['SalePrice']\n",
    "\n",
    "results_df.index += 1461\n",
    "results_df.index.name = 'Id'\n",
    "\n",
    "results_df.to_csv('./kaggle/results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
